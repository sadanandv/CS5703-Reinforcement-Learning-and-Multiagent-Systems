{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bedfca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harip\\AppData\\Local\\Temp\\ipykernel_12232\\3662425227.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Value for the Test State: [[-0.0730509   0.03693237]\n",
      " [-0.40206735  0.21885557]]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "def feature_extractor(state):\n",
    "    \"\"\"\n",
    "    Simple feature extractor for state representation.\n",
    "\n",
    "    Parameters:\n",
    "    - state: Current state from the environment.\n",
    "\n",
    "    Returns:\n",
    "    - features: Extracted features from the state.\n",
    "    \"\"\"\n",
    "    # For simplicity, use the state itself as features\n",
    "    return np.array(state)\n",
    "\n",
    "def linear_function_approximation(weights, features):\n",
    "\n",
    "    return np.dot(weights, features)\n",
    "\n",
    "def td_prediction(env, num_episodes, alpha, gamma):\n",
    "    \"\"\"\n",
    "    Temporal Difference (TD) prediction for state values using linear function approximation.\n",
    "\n",
    "    Parameters:\n",
    "    - env: Gym environment.\n",
    "    - num_episodes: Number of episodes for training.\n",
    "    - alpha: Learning rate.\n",
    "    - gamma: Discount factor.\n",
    "\n",
    "    Returns:\n",
    "    - weights: Learned weights for the linear approximation.\n",
    "    \"\"\"\n",
    "    num_features = len(feature_extractor(env.reset()))\n",
    "    weights = np.zeros((num_features,num_features))\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        features = feature_extractor(state)[0]\n",
    "        features = np.array(features).reshape(2,2)\n",
    "        while True:\n",
    "            # Choose an action using an exploration-exploitation strategy (e.g., epsilon-greedy)\n",
    "            action = env.action_space.sample()  # Random action for illustration\n",
    "\n",
    "            # Take the chosen action and observe the next state and reward\n",
    "            next_state, reward, done, a , b = env.step(action)\n",
    "            next_features = feature_extractor(next_state)\n",
    "            next_features = np.array(next_features).reshape(2,2)\n",
    "            # TD error calculation\n",
    "            td_error = reward + gamma * linear_function_approximation(weights, next_features) - \\\n",
    "                       linear_function_approximation(weights, features)\n",
    "\n",
    "            # Update weights based on the TD error and features\n",
    "            #print(alpha * td_error * features)\n",
    "            weights += alpha * td_error * features\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "            features = next_features\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Example usage:\n",
    "env = gym.make('CartPole-v1')\n",
    "num_episodes = 1000\n",
    "alpha = 0.01\n",
    "gamma = 0.99\n",
    "\n",
    "learned_weights = td_prediction(env, num_episodes, alpha, gamma)\n",
    "\n",
    "# Test the learned weights\n",
    "test_state = env.reset()\n",
    "test_features = feature_extractor(test_state)\n",
    "estimated_value = linear_function_approximation(learned_weights, np.array(test_features)[0].reshape(2,2))\n",
    "print(\"Estimated Value for the Test State:\", estimated_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
